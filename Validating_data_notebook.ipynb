{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5371cda3",
   "metadata": {},
   "source": [
    "# Validating data notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f418367",
   "metadata": {},
   "source": [
    "#### In this notebook is a demonesrtaion of how to validate data using another data source\n",
    "\n",
    "This is done using a data `pipeline` that will ingest and clean our data with the press of a button"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e725a",
   "metadata": {},
   "source": [
    "we will use a dataset from an imaginary country called `Maji Ndogo` created by `Explore-AI` academy\n",
    "the dataset is containing agricultural data about the fields of `Maji Ndogo`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc719458",
   "metadata": {},
   "source": [
    "the dataset contains a wheater data and we will validate these data using a data collected from a weather stations in the area of each field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1548521f",
   "metadata": {},
   "source": [
    "Our main goal is: Is the data in our `MD_agric_df` dataset representative of reality? To answer this, we use weather-related data from nearby stations to validate our results. If the weather data matches the data we have, we can be more confident that our dataset represents reality. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ba18a",
   "metadata": {},
   "source": [
    "So what's the plan? \n",
    "1. Create a null hypothesis.\n",
    "1. Import the `MD_agric_df` dataset and clean it up.\n",
    "1. Import the weather data.\n",
    "1. Map the weather data to the field data.\n",
    "1. Calculate the means of the weather station dataset and the means of the main dataset.\n",
    "2. Calculate all the parameters we need to do a t-test. \n",
    "3. Interpret our results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c47bb5",
   "metadata": {},
   "source": [
    "# Data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f3cfa1",
   "metadata": {},
   "source": [
    "**1. Geographic features**\n",
    "\n",
    "- **Field_ID:** A unique identifier for each field (BigInt).\n",
    " \n",
    "- **Elevation:** The elevation of the field above sea level in metres (Float).\n",
    "\n",
    "- **Latitude:** Geographical latitude of the field in degrees (Float).\n",
    "\n",
    "- **Longitude:** Geographical longitude of the field in degrees (Float).\n",
    "\n",
    "- **Location:** Province the field is in (Text).\n",
    "\n",
    "- **Slope:** The slope of the land in the field (Float).\n",
    "\n",
    "**2. Weather features**\n",
    "\n",
    "- **Field_ID:** Corresponding field identifier (BigInt).\n",
    "\n",
    "- **Rainfall:** Amount of rainfall in the area in mm (Float).\n",
    "\n",
    "- **Min_temperature_C:** Average minimum temperature recorded in Celsius (Float).\n",
    "\n",
    "- **Max_temperature_C:** Average maximum temperature recorded in Celsius (Float).\n",
    "\n",
    "- **Ave_temps:** Average temperature in Celcius (Float).\n",
    "\n",
    "**3. Soil and crop features**\n",
    "\n",
    "- **Field_ID:** Corresponding field identifier (BigInt).\n",
    "\n",
    "- **Soil_fertility:** A measure of soil fertility where 0 is infertile soil, and 1 is very fertile soil (Float).\n",
    "\n",
    "- **Soil_type:** Type of soil present in the field (Text).\n",
    "\n",
    "- **pH:** pH level of the soil, which is a measure of how acidic/basic the soil is (Float).\n",
    "\n",
    "**4. Farm management features**\n",
    "\n",
    "- **Field_ID:** Corresponding field identifier (BigInt).\n",
    "\n",
    "- **Pollution_level:** Level of pollution in the area where 0 is unpolluted and 1 is very polluted (Float).\n",
    "\n",
    "- **Plot_size:** Size of the plot in the field (Ha) (Float).\n",
    "\n",
    "- **Chosen_crop:** Type of crop chosen for cultivation (Text).\n",
    "\n",
    "- **Annual_yield:** Annual yield from the field (Float). This is the total output of the field. The field size and type of crop will affect the Annual Yield\n",
    "\n",
    "- **Standard_yield:** Standardised yield expected from the field, normalised per crop (Float). This is independent of field size, or crop type. Multiplying this number by the field size, and average crop yield will give the Annual_Yield.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Weather_station_data (CSV)**\n",
    "\n",
    "- **Weather_station_ID:** The weather station the data originated from. (Int)\n",
    "\n",
    "- **Message:** The weather data was captured by sensors at the stations, in the format of text messages.(Str)\n",
    "\n",
    "**Weather_data_field_mapping (CSV)**\n",
    "\n",
    "- **Field_ID:** The id of the field that is connected to a weather station. This is the key we can use to join the weather station ID to the original data. (Int)\n",
    "\n",
    "- **Weather_station_ID:** The weather station that is connected to a field. If a field has `weather_station_ID = 0` then that field is closest to weather station 0. (Int)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7413a4",
   "metadata": {},
   "source": [
    "# Dealing with a friendly warning from Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862b309",
   "metadata": {},
   "source": [
    "If you are running this notebook in `Python 3.12` or later, you might get a warning if you run the imports below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff4521",
   "metadata": {},
   "source": [
    "If you are lucky enough to see this warning, it let's us know that Pandas is changing soon and will require another package to be installed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6ba10",
   "metadata": {},
   "source": [
    "```python\n",
    "...2334042735.py:3: DeprecationWarning: \n",
    "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
    "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
    "but was not found to be installed on your system.\n",
    "If this would cause problems for you,\n",
    "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
    "        \n",
    "  import pandas as pd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0febb",
   "metadata": {},
   "source": [
    "We can safely ignore these warnings, but soon our script will fail to import Pandas, so let's fix it today, and we won't have to worry about it for a long time. The warning tells us that Pyarrow will soon be a requirement to import Pandas, so we can just install it with pip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install Pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b715617",
   "metadata": {},
   "source": [
    "# Creating up our data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a427b29",
   "metadata": {},
   "source": [
    "So here's the plan: \n",
    "\n",
    "1. Create a module for each step.\n",
    "\n",
    "2. We will create three modules: \n",
    "\n",
    "    a. `data_ingesation.py` - All SQL-related functions, and web-based data retrieval.\n",
    "\n",
    "    b. `field_data_processor.py` - All transformations, cleanup, and merging functionality.\n",
    "\n",
    "    c. `weather_data_processor.py` - All transformations and cleanup of the weather station data.\n",
    "\n",
    "3. Test the modules functionality.\n",
    "\n",
    "4. Create automated data validation tests to ensure our data is as we expect it to be.\n",
    "\n",
    "Once we're done with that, we're going to jump into the reason why we're here. So let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa809d",
   "metadata": {},
   "source": [
    "The first challenge; automating the data ingestion. There are two places we're fetching data:\n",
    "1. SQLite database - We need to create an SQLite engine, connect to the database, run a query and return a pandas DataFrame.\n",
    "2. Web CSV file - Read the CSV data from the web, and import it as a DataFrame.\n",
    "\n",
    "So let's start building!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3401e792",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f0f29",
   "metadata": {},
   "source": [
    "Creating modules in Jupyter notebooks is a bit of a pain. If we make changes to the `module.py` file, we have to restart the notebook kernel and import the module again in order to apply those changes. So, we're going to fully develop it, test it in this notebook, and only then, move it to a `data_ingestion.py` file, and import it. \n",
    "\n",
    "To create a module, our code should ideally be encapsulated in functions or classes. How do we choose?\n",
    "\n",
    "Since the process of connecting to a database, and querying some data is relatively straightforward, functions seemed like the best fit. Functions allow us to encapsulate the necessary steps in clear, reusable blocks of code without the overhead of managing class objects. It's like using a **simple tool** for a specific task â€” pick it up, use it, and put it back without needing to remember anything about the last use.\n",
    "\n",
    "On the other hand, our **data processing** modules are a bit more complex. These modules not only perform various operations on the data but also need to keep track of the data as it goes through these processes. For this, we use **classes** to **create DataFrame objects** as attributes. This approach simplifies data handling since we're passing the object around, which inherently knows its data and the operations it can perform within the class.\n",
    "\n",
    "This idea ties back to OOP. Class objects are designed to deal with data and operations on that data via methods, while functions are made to do the simpler tasks.\n",
    "\n",
    "So for **data ingestion**, we're just going to use functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4143f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce5c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_engine(db_path):\n",
    "    engine = create_engine(db_path)\n",
    "    return engine\n",
    "\n",
    "def query_data(engine, sql_query):\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql_query(text(sql_query), connection)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb325c6",
   "metadata": {},
   "source": [
    "# Here is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a35ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field_ID</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Min_temperature_C</th>\n",
       "      <th>Max_temperature_C</th>\n",
       "      <th>Ave_temps</th>\n",
       "      <th>Soil_fertility</th>\n",
       "      <th>Soil_type</th>\n",
       "      <th>pH</th>\n",
       "      <th>Pollution_level</th>\n",
       "      <th>Plot_size</th>\n",
       "      <th>Crop_type</th>\n",
       "      <th>Annual_yield</th>\n",
       "      <th>Standard_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40734</td>\n",
       "      <td>786.05580</td>\n",
       "      <td>-7.389911</td>\n",
       "      <td>-7.556202</td>\n",
       "      <td>Rural_Akatsi</td>\n",
       "      <td>14.795113</td>\n",
       "      <td>1125.2</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>33.1</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>6.169393</td>\n",
       "      <td>8.526684e-02</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.751354</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.577964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30629</td>\n",
       "      <td>674.33410</td>\n",
       "      <td>-7.736849</td>\n",
       "      <td>-1.051539</td>\n",
       "      <td>Rural_Sokoto</td>\n",
       "      <td>11.374611</td>\n",
       "      <td>1450.7</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>30.6</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Volcanic</td>\n",
       "      <td>5.676648</td>\n",
       "      <td>3.996838e-01</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.069865</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.486302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39924</td>\n",
       "      <td>826.53390</td>\n",
       "      <td>-9.926616</td>\n",
       "      <td>0.115156</td>\n",
       "      <td>Rural_Sokoto</td>\n",
       "      <td>11.339692</td>\n",
       "      <td>2208.9</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.69</td>\n",
       "      <td>Volcanic</td>\n",
       "      <td>5.331993</td>\n",
       "      <td>3.580286e-01</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.208801</td>\n",
       "      <td>tea</td>\n",
       "      <td>0.649647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5754</td>\n",
       "      <td>574.94617</td>\n",
       "      <td>-2.420131</td>\n",
       "      <td>-6.592215</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>7.109855</td>\n",
       "      <td>328.8</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>32.2</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Loamy</td>\n",
       "      <td>5.328150</td>\n",
       "      <td>2.866871e-01</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.277635</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.532348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14146</td>\n",
       "      <td>886.35300</td>\n",
       "      <td>-3.055434</td>\n",
       "      <td>-7.952609</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>55.007656</td>\n",
       "      <td>785.2</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.25</td>\n",
       "      <td>0.72</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.721234</td>\n",
       "      <td>4.319027e-02</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.832614</td>\n",
       "      <td>wheat</td>\n",
       "      <td>0.555076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>11472</td>\n",
       "      <td>681.36145</td>\n",
       "      <td>-7.358371</td>\n",
       "      <td>-6.254369</td>\n",
       "      <td>Rural_Akatsi</td>\n",
       "      <td>16.213196</td>\n",
       "      <td>885.7</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>14.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.741063</td>\n",
       "      <td>3.286828e-01</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.609930</td>\n",
       "      <td>potato</td>\n",
       "      <td>0.554482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>19660</td>\n",
       "      <td>667.02120</td>\n",
       "      <td>-3.154559</td>\n",
       "      <td>-4.475046</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>2.397553</td>\n",
       "      <td>501.1</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>13.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.445833</td>\n",
       "      <td>1.602583e-01</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.812289</td>\n",
       "      <td>maize</td>\n",
       "      <td>0.438194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>41296</td>\n",
       "      <td>670.77900</td>\n",
       "      <td>-14.472861</td>\n",
       "      <td>-6.110221</td>\n",
       "      <td>Rural_Hawassa</td>\n",
       "      <td>7.636470</td>\n",
       "      <td>1586.6</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>33.4</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Volcanic</td>\n",
       "      <td>5.385873</td>\n",
       "      <td>8.221326e-09</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.681629</td>\n",
       "      <td>tea</td>\n",
       "      <td>0.800776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5652</th>\n",
       "      <td>33090</td>\n",
       "      <td>429.48840</td>\n",
       "      <td>-14.653089</td>\n",
       "      <td>-6.984116</td>\n",
       "      <td>Rural_Hawassa</td>\n",
       "      <td>13.944720</td>\n",
       "      <td>1272.2</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>34.6</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>Silt</td>\n",
       "      <td>5.562508</td>\n",
       "      <td>6.917245e-10</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.659874</td>\n",
       "      <td>cassava</td>\n",
       "      <td>0.507595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>8375</td>\n",
       "      <td>763.09030</td>\n",
       "      <td>-4.317028</td>\n",
       "      <td>-6.344461</td>\n",
       "      <td>Rural_Kilimani</td>\n",
       "      <td>35.189430</td>\n",
       "      <td>516.4</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>29.6</td>\n",
       "      <td>12.90</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>5.087792</td>\n",
       "      <td>2.612715e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.226532</td>\n",
       "      <td>wheat</td>\n",
       "      <td>0.453064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5654 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Field_ID  Elevation   Latitude  Longitude        Location      Slope  \\\n",
       "0        40734  786.05580  -7.389911  -7.556202    Rural_Akatsi  14.795113   \n",
       "1        30629  674.33410  -7.736849  -1.051539    Rural_Sokoto  11.374611   \n",
       "2        39924  826.53390  -9.926616   0.115156    Rural_Sokoto  11.339692   \n",
       "3         5754  574.94617  -2.420131  -6.592215  Rural_Kilimani   7.109855   \n",
       "4        14146  886.35300  -3.055434  -7.952609  Rural_Kilimani  55.007656   \n",
       "...        ...        ...        ...        ...             ...        ...   \n",
       "5649     11472  681.36145  -7.358371  -6.254369    Rural_Akatsi  16.213196   \n",
       "5650     19660  667.02120  -3.154559  -4.475046  Rural_Kilimani   2.397553   \n",
       "5651     41296  670.77900 -14.472861  -6.110221   Rural_Hawassa   7.636470   \n",
       "5652     33090  429.48840 -14.653089  -6.984116   Rural_Hawassa  13.944720   \n",
       "5653      8375  763.09030  -4.317028  -6.344461  Rural_Kilimani  35.189430   \n",
       "\n",
       "      Rainfall  Min_temperature_C  Max_temperature_C  Ave_temps  \\\n",
       "0       1125.2               -3.1               33.1      15.00   \n",
       "1       1450.7               -3.9               30.6      13.35   \n",
       "2       2208.9               -1.8               28.4      13.30   \n",
       "3        328.8               -5.8               32.2      13.20   \n",
       "4        785.2               -2.5               31.0      14.25   \n",
       "...        ...                ...                ...        ...   \n",
       "5649     885.7               -4.3               33.4      14.55   \n",
       "5650     501.1               -4.8               32.1      13.65   \n",
       "5651    1586.6               -3.8               33.4      14.80   \n",
       "5652    1272.2               -6.2               34.6      14.20   \n",
       "5653     516.4               -3.8               29.6      12.90   \n",
       "\n",
       "      Soil_fertility Soil_type        pH  Pollution_level  Plot_size  \\\n",
       "0               0.62     Sandy  6.169393     8.526684e-02        1.3   \n",
       "1               0.64  Volcanic  5.676648     3.996838e-01        2.2   \n",
       "2               0.69  Volcanic  5.331993     3.580286e-01        3.4   \n",
       "3               0.54     Loamy  5.328150     2.866871e-01        2.4   \n",
       "4               0.72     Sandy  5.721234     4.319027e-02        1.5   \n",
       "...              ...       ...       ...              ...        ...   \n",
       "5649            0.61     Sandy  5.741063     3.286828e-01        1.1   \n",
       "5650            0.54     Sandy  5.445833     1.602583e-01        8.7   \n",
       "5651            0.64  Volcanic  5.385873     8.221326e-09        2.1   \n",
       "5652            0.63      Silt  5.562508     6.917245e-10        1.3   \n",
       "5653            0.64     Sandy  5.087792     2.612715e-01        0.5   \n",
       "\n",
       "      Crop_type Annual_yield  Standard_yield  \n",
       "0      0.751354      cassava        0.577964  \n",
       "1      1.069865      cassava        0.486302  \n",
       "2      2.208801          tea        0.649647  \n",
       "3      1.277635      cassava        0.532348  \n",
       "4      0.832614        wheat        0.555076  \n",
       "...         ...          ...             ...  \n",
       "5649   0.609930       potato        0.554482  \n",
       "5650   3.812289        maize        0.438194  \n",
       "5651   1.681629          tea        0.800776  \n",
       "5652   0.659874      cassava        0.507595  \n",
       "5653   0.226532        wheat        0.453064  \n",
       "\n",
       "[5654 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL_engine = create_db_engine('sqlite:///Maji_Ndogo_farm_survey_small.db')\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = query_data(SQL_engine, sql_query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90ea3c",
   "metadata": {},
   "source": [
    "This seems simple, but let's think for a second about what could go wrong. For example, what if there is a problem like the database has a schema, and no actual data? Or our query doesn't return any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9e6a6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field_ID</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Min_temperature_C</th>\n",
       "      <th>Max_temperature_C</th>\n",
       "      <th>Ave_temps</th>\n",
       "      <th>Soil_fertility</th>\n",
       "      <th>Soil_type</th>\n",
       "      <th>pH</th>\n",
       "      <th>Pollution_level</th>\n",
       "      <th>Plot_size</th>\n",
       "      <th>Crop_type</th>\n",
       "      <th>Annual_yield</th>\n",
       "      <th>Standard_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Field_ID, Elevation, Latitude, Longitude, Location, Slope, Rainfall, Min_temperature_C, Max_temperature_C, Ave_temps, Soil_fertility, Soil_type, pH, Pollution_level, Plot_size, Crop_type, Annual_yield, Standard_yield]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL_engine = create_db_engine('sqlite:///Maji_Ndogo_farm_survey_small.db')\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "WHERE Rainfall < 0 \n",
    "\"\"\"\n",
    "# The last line won't ever be true, so no results will be returned. \n",
    "\n",
    "df = query_data(SQL_engine, sql_query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ffe6d1",
   "metadata": {},
   "source": [
    "We get an empty DataFrame, because SQL returned an empty query result. When we try to filter results, we get an answer that would not make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7cbf2",
   "metadata": {},
   "source": [
    "So to avoid this we need to add error handling into our code so that we stop the process if something is wrong, and tell us what the problem is before we continue. \n",
    "\n",
    "Secondly, to help us understand how our code is executing we're going to add some logs. While print statements can help us to debug our code, we have to remove them once our code goes into use, one by one. `logging` is a better way to debug our code than print statements because we can add `logging.INFO()` logs to know what our code is doing, and `logging.DEBUG()` statements that have more detail in case we want to debug a specific loop in a bit more in detail. There are also various other tools to use, and we can also silence all logging with a single line of code. If we used print statements, we will have to comment them out one by one. \n",
    "\n",
    "If we apply these two ideas, we get the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b83ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Name our logger so we know that logs from this module come from the data_ingestion module\n",
    "logger = logging.getLogger('data_ingestion')\n",
    "\n",
    "# Set a basic logging message up that prints out a timestamp, the name of our logger, and the message\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "def create_db_engine(db_path):\n",
    "    try:\n",
    "        engine = create_engine(db_path)\n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            pass\n",
    "        # test if the database engine was created successfully\n",
    "        logger.info(\"Database engine created successfully.\")\n",
    "        return engine # Return the engine object if it all works well\n",
    "    except ImportError: #If we get an ImportError, inform the user SQLAlchemy is not installed\n",
    "        logger.error(\"SQLAlchemy is required to use this function. Please install it first.\")\n",
    "        raise e\n",
    "    except Exception as e:# If we fail to create an engine inform the user\n",
    "        logger.error(f\"Failed to create database engine. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "def query_data(engine, sql_query):\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            df = pd.read_sql_query(text(sql_query), connection)\n",
    "        if df.empty:\n",
    "            # Log a message or handle the empty DataFrame scenario as needed\n",
    "            logger.error(\"The query returned an empty DataFrame.\")\n",
    "            raise ValueError(\"The query returned an empty DataFrame.\")\n",
    "        logger.info(\"Query executed successfully.\")\n",
    "        return df\n",
    "    except ValueError as e: \n",
    "        logger.error(f\"SQL query failed. Error: {e}\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while querying the database. Error: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ee942",
   "metadata": {},
   "source": [
    "Now when we run the incorrect query again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb6f078b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 18:05:12,994 - data_ingestion - INFO - Database engine created successfully.\n",
      "2024-03-01 18:05:12,998 - data_ingestion - ERROR - The query returned an empty DataFrame.\n",
      "2024-03-01 18:05:12,998 - data_ingestion - ERROR - SQL query failed. Error: The query returned an empty DataFrame.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The query returned an empty DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m      3\u001b[0m sql_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mSELECT *\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124mFROM geographic_features\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mWHERE Rainfall < 0 \u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# The last line won't ever be true, so no results will be returned. \u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m query_data(SQL_engine, sql_query)\n\u001b[0;32m     14\u001b[0m df\n",
      "Cell \u001b[1;32mIn[14], line 39\u001b[0m, in \u001b[0;36mquery_data\u001b[1;34m(engine, sql_query)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[0;32m     38\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSQL query failed. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     41\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while querying the database. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 34\u001b[0m, in \u001b[0;36mquery_data\u001b[1;34m(engine, sql_query)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Log a message or handle the empty DataFrame scenario as needed\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe query returned an empty DataFrame.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe query returned an empty DataFrame.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery executed successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[1;31mValueError\u001b[0m: The query returned an empty DataFrame."
     ]
    }
   ],
   "source": [
    "SQL_engine = create_db_engine('sqlite:///Maji_Ndogo_farm_survey_small.db')\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "WHERE Rainfall < 0 \n",
    "\"\"\"\n",
    "# The last line won't ever be true, so no results will be returned. \n",
    "\n",
    "df = query_data(SQL_engine, sql_query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56a965",
   "metadata": {},
   "source": [
    "Next up, let's include the CSV data handling. This is the original code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5457a12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 18:12:25,897 - data_ingestion - INFO - CSV file read successfully from the web.\n",
      "2024-03-01 18:12:26,725 - data_ingestion - INFO - CSV file read successfully from the web.\n"
     ]
    }
   ],
   "source": [
    "weather_data_URL = \"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv\"\n",
    "weather_mapping_data_URL = \"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_data_field_mapping.csv\"\n",
    "\n",
    "\n",
    "def read_from_web_CSV(URL):\n",
    "    try:\n",
    "        df = pd.read_csv(URL)\n",
    "        logger.info(\"CSV file read successfully from the web.\")\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        logger.error(\"The URL does not point to a valid CSV file. Please check the URL and try again.\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read CSV from the web. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "    \n",
    "weather_df = read_from_web_CSV(weather_data_URL)\n",
    "weather_mapping_data = read_from_web_CSV(weather_mapping_data_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c104ae30",
   "metadata": {},
   "source": [
    "Great! Now our code can connect to a database for the field data, use a query to retrieve data and create a DataFrame. We can also import CSV files from a URL into a DataFrame, and avoid pulling unexpected data. If we put all this code together we have the basic structure of our module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd844692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Name our logger so we know that logs from this module come from the data_ingestion module\n",
    "logger = logging.getLogger('data_ingestion')\n",
    "# Set a basic logging message up that prints out a timestamp, the name of our logger, and the message\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "db_path = 'sqlite:///Maji_Ndogo_farm_survey_small.db'\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features\n",
    "LEFT JOIN weather_features USING (Field_ID)\n",
    "LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "LEFT JOIN farm_management_features USING (Field_ID)\n",
    "\"\"\"\n",
    "\n",
    "weather_data_URL = \"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv\"\n",
    "weather_mapping_data_URL = \"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_data_field_mapping.csv\"\n",
    "\n",
    "def create_db_engine(db_path):\n",
    "    try:\n",
    "        engine = create_engine(db_path)\n",
    "        # Test connection\n",
    "        with engine.connect() as conn:\n",
    "            pass\n",
    "        # test if the database engine was created successfully\n",
    "        logger.info(\"Database engine created successfully.\")\n",
    "        return engine # Return the engine object if it all works well\n",
    "    except ImportError: #If we get an ImportError, inform the user SQLAlchemy is not installed\n",
    "        logger.error(\"SQLAlchemy is required to use this function. Please install it first.\")\n",
    "        raise e\n",
    "    except Exception as e:# If we fail to create an engine inform the user\n",
    "        logger.error(f\"Failed to create database engine. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "def query_data(engine, sql_query):\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            df = pd.read_sql_query(text(sql_query), connection)\n",
    "        if df.empty:\n",
    "            # Log a message or handle the empty DataFrame scenario as needed\n",
    "            msg = \"The query returned an empty DataFrame.\"\n",
    "            logger.error(msg)\n",
    "            raise ValueError(msg)\n",
    "        logger.info(\"Query executed successfully.\")\n",
    "        return df\n",
    "    except ValueError as e: \n",
    "        logger.error(f\"SQL query failed. Error: {e}\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while querying the database. Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "def read_from_web_CSV(URL):\n",
    "    try:\n",
    "        df = pd.read_csv(URL)\n",
    "        logger.info(\"CSV file read successfully from the web.\")\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        logger.error(\"The URL does not point to a valid CSV file. Please check the URL and try again.\")\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read CSV from the web. Error: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9f9e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 18:13:51,424 - data_ingestion - INFO - Database engine created successfully.\n",
      "2024-03-01 18:13:51,493 - data_ingestion - INFO - Query executed successfully.\n",
      "2024-03-01 18:13:52,257 - data_ingestion - INFO - CSV file read successfully from the web.\n",
      "2024-03-01 18:13:52,945 - data_ingestion - INFO - CSV file read successfully from the web.\n"
     ]
    }
   ],
   "source": [
    "# Testing module functions  \n",
    "field_df = query_data(create_db_engine(db_path), sql_query)   \n",
    "weather_df = read_from_web_CSV(weather_data_URL)\n",
    "weather_mapping_df = read_from_web_CSV(weather_mapping_data_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8013ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
